{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2db60a-3032-486a-b0a9-161ae5722377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misaki/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/misaki/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "2025-01-05 22:51:03.455216: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-05 22:51:03.462707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-05 22:51:03.471335: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-05 22:51:03.473815: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-05 22:51:03.480331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-05 22:51:03.997542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB: stock_data.daily_prices\n",
      "Fetched 5000 records for symbol 'QQQ'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from data_pipeline.mongodb_accessor import StockDataMongoDB\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load the data\n",
    "mongo_accessor = StockDataMongoDB()\n",
    "data = mongo_accessor.get_stock_data(\"QQQ\")\n",
    "data = data[['close', 'volume']]\n",
    "\n",
    "# Calculate additional features\n",
    "data['price_diff'] = data['close'].diff()  # Difference between consecutive prices\n",
    "data['direction'] = (data['price_diff'] > 0).astype(int)  # Direction label (1 for up, 0 for down)\n",
    "\n",
    "# Drop NaN values created by `diff`\n",
    "data = data.sort_index().dropna()\n",
    "\n",
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0798d239-9fe2-4d09-9b09-50e7bd059297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          close     volume  price_diff  direction\n",
      "0     518.58002   29002300     8.35001          1\n",
      "1     510.23001   36389800    -1.00000          0\n",
      "2     511.23001   29117000    -4.37998          0\n",
      "3     515.60999   34584000    -6.95001          0\n",
      "4     522.56000   33839600    -7.03998          0\n",
      "...         ...        ...         ...        ...\n",
      "4994   37.61000  107270600    -0.02000          0\n",
      "4995   37.63000   78460600     0.41000          1\n",
      "4996   37.22000   95731300    -0.40000          0\n",
      "4997   37.62000   79988700     0.21000          1\n",
      "4998   37.41000   99334600     0.47000          1\n",
      "\n",
      "[4999 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39aaae12-99ab-4976-869d-db7004acb9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n",
      "Input shape (X): (4939, 60, 3)\n",
      "Output shape (y): (4939,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "features = data[['close', 'volume', 'price_diff']].values\n",
    "target = data['direction'].values  # Predicting direction (classification)\n",
    "\n",
    "# Separate scalers for price, volume, and price_diff\n",
    "price_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "volume_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "diff_scaler = MinMaxScaler(feature_range=(-1, 1))  # Scaled between -1 and 1 for difference\n",
    "\n",
    "scaled_price = price_scaler.fit_transform(features[:, 0].reshape(-1, 1))\n",
    "scaled_volume = volume_scaler.fit_transform(features[:, 1].reshape(-1, 1))\n",
    "scaled_diff = diff_scaler.fit_transform(features[:, 2].reshape(-1, 1))\n",
    "\n",
    "# Combine scaled features\n",
    "scaled_data = np.hstack((scaled_price, scaled_volume, scaled_diff))\n",
    "\n",
    "# Create sequences for LSTM input\n",
    "def create_sequences(data, labels, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i])  # Last `seq_length` rows as input\n",
    "        y.append(labels[i])  # Current row's direction as the target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_data, target, seq_length)\n",
    "print(y)\n",
    "# Ensure shapes are correct\n",
    "print(\"Input shape (X):\", X.shape)  # (n_samples, seq_length, n_features)\n",
    "print(\"Output shape (y):\", y.shape)  # (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be58264-a79d-4f3f-a2e9-9804497a880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5357 - loss: 0.6913\n",
      "Epoch 2/40\n",
      "\u001b[1m16/94\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5703 - loss: 0.6833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736147246.681146  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.681580  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.681971  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.682319  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.682670  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.683032  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.683372  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.683715  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.684058  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.684435  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.684809  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.685170  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.685531  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.685932  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.686290  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.686654  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.687026  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.687422  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.687789  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.688156  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.688563  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.688941  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.689360  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.689727  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.690143  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.690737  194494 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.700482  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.700883  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.701808  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.702270  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.702672  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.703077  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.703467  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.703836  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.704200  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.704579  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.704972  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.705440  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.705884  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.706364  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.706750  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.707223  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.707633  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1736147246.708129  194499 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5594 - loss: 0.6852\n",
      "Epoch 3/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5741 - loss: 0.6830\n",
      "Epoch 4/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5659 - loss: 0.6838\n",
      "Epoch 5/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5565 - loss: 0.6833\n",
      "Epoch 6/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5770 - loss: 0.6769\n",
      "Epoch 7/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5732 - loss: 0.6785\n",
      "Epoch 8/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5653 - loss: 0.6794\n",
      "Epoch 9/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5751 - loss: 0.6750\n",
      "Epoch 10/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5847 - loss: 0.6740\n",
      "Epoch 11/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5873 - loss: 0.6722\n",
      "Epoch 12/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5814 - loss: 0.6731\n",
      "Epoch 13/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5964 - loss: 0.6655\n",
      "Epoch 14/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5770 - loss: 0.6733\n",
      "Epoch 15/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5847 - loss: 0.6747\n",
      "Epoch 16/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5908 - loss: 0.6662\n",
      "Epoch 17/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5901 - loss: 0.6764\n",
      "Epoch 18/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5865 - loss: 0.6660\n",
      "Epoch 19/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5891 - loss: 0.6745\n",
      "Epoch 20/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5853 - loss: 0.6721\n",
      "Epoch 21/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 0.6605\n",
      "Epoch 22/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5919 - loss: 0.6686\n",
      "Epoch 23/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5902 - loss: 0.6696\n",
      "Epoch 24/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5890 - loss: 0.6657\n",
      "Epoch 25/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5942 - loss: 0.6663\n",
      "Epoch 26/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 0.6573\n",
      "Epoch 27/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5958 - loss: 0.6618\n",
      "Epoch 28/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 0.6644\n",
      "Epoch 29/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5970 - loss: 0.6622\n",
      "Epoch 30/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 0.6634\n",
      "Epoch 31/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5940 - loss: 0.6687\n",
      "Epoch 32/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5741 - loss: 0.6695\n",
      "Epoch 33/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6124 - loss: 0.6563\n",
      "Epoch 34/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5976 - loss: 0.6586\n",
      "Epoch 35/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6237 - loss: 0.6490\n",
      "Epoch 36/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5915 - loss: 0.6608\n",
      "Epoch 37/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6177 - loss: 0.6482\n",
      "Epoch 38/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6080 - loss: 0.6535\n",
      "Epoch 39/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5968 - loss: 0.6594\n",
      "Epoch 40/40\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 0.6541\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f56ec0816c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified model to accept 2 features\n",
    "# Build the model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add 1D Convolutional layer\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Stack LSTM layers\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=32, return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Dense output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',  # Metric to monitor (e.g., 'val_loss', 'val_accuracy')\n",
    "    patience=3,          # Number of epochs with no improvement before stopping\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "\n",
    "# Initialization phase\n",
    "initialization_size = 3000\n",
    "X_initial = X[:initialization_size]\n",
    "y_initial = y[:initialization_size]\n",
    "\n",
    "model = build_model((X_initial.shape[1], 3))  # Note the 2 for 2 features\n",
    "model.fit(X_initial, y_initial, batch_size=32, epochs=40, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5f5e3c-fd84-4d9c-aeb6-2365f6eefc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directional Backtesting: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1998/1998 [01:08<00:00, 29.14it/s, Accuracy=45.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directional Prediction Results:\n",
      "Total Predictions: 1998\n",
      "Correct Predictions: 900\n",
      "Final Accuracy: 45.05%\n",
      "\n",
      "Baseline Comparison:\n",
      "Random Guessing Expected Accuracy: 50.00%\n",
      "Model Improvement over Random: -4.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def directional_backtest(model, data, price_scaler, volume_scaler, diff_scaler, seq_length, batch_size=64):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    X_buffer = []\n",
    "    y_buffer = []\n",
    "\n",
    "    with tqdm(total=len(data) - initialization_size - 1, desc='Directional Backtesting') as pbar:\n",
    "        for i in range(initialization_size, len(data) - 1):\n",
    "            # Prepare sequences for price, volume, and price_diff\n",
    "            current_sequence_price = data[i-seq_length:i, 0].reshape(-1, 1)\n",
    "            current_sequence_volume = data[i-seq_length:i, 1].reshape(-1, 1)\n",
    "            current_sequence_diff = data[i-seq_length:i, 2].reshape(-1, 1)\n",
    "\n",
    "            # Scale features\n",
    "            scaled_price_seq = price_scaler.transform(current_sequence_price)\n",
    "            scaled_volume_seq = volume_scaler.transform(current_sequence_volume)\n",
    "            scaled_diff_seq = diff_scaler.transform(current_sequence_diff)\n",
    "\n",
    "            # Combine and reshape\n",
    "            current_sequence = np.hstack((scaled_price_seq, scaled_volume_seq, scaled_diff_seq))\n",
    "            current_sequence = np.reshape(current_sequence, (1, seq_length, 3))  # Adjust for 3 features\n",
    "\n",
    "            # Make prediction\n",
    "            predicted_value = model.predict(current_sequence, verbose=0)\n",
    "            predicted_value = price_scaler.inverse_transform(predicted_value)  # Inverse scale prediction to original price scale\n",
    "\n",
    "            # Get current and next actual prices\n",
    "            current_price = data[i, 0]\n",
    "            next_price = data[i + 1, 0]\n",
    "\n",
    "            # Check directional accuracy\n",
    "            price_went_up = next_price > current_price\n",
    "            predicted_up = predicted_value[0][0] > current_price\n",
    "\n",
    "            if price_went_up == predicted_up:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "\n",
    "            current_accuracy = (correct_predictions / total_predictions) * 100\n",
    "            pbar.set_postfix({'Accuracy': f'{current_accuracy:.2f}%'})\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Update model with new data (price, volume, diff)\n",
    "            X_buffer.append(current_sequence[0])\n",
    "            y_new = price_scaler.transform(np.array([[data[i + 1, 0]]]))  # Use next price as target\n",
    "            y_buffer.append(y_new.flatten()[0])\n",
    "\n",
    "            if len(X_buffer) == batch_size:\n",
    "                X_batch = np.array(X_buffer)\n",
    "                y_batch = np.array(y_buffer)\n",
    "                # model.fit(X_batch, y_batch, epochs=20, batch_size=batch_size, verbose=0)\n",
    "                X_buffer = []\n",
    "                y_buffer = []\n",
    "\n",
    "    # Final update for any remaining buffered data\n",
    "    if X_buffer:\n",
    "        X_batch = np.array(X_buffer)\n",
    "        y_batch = np.array(y_buffer)\n",
    "        # model.fit(X_batch, y_batch, epochs=20, batch_size=len(X_buffer), verbose=0)\n",
    "\n",
    "    final_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nDirectional Prediction Results:\")\n",
    "    print(f\"Total Predictions: {total_predictions}\")\n",
    "    print(f\"Correct Predictions: {correct_predictions}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy:.2f}%\")\n",
    "    print(f\"\\nBaseline Comparison:\")\n",
    "    print(f\"Random Guessing Expected Accuracy: 50.00%\")\n",
    "    print(f\"Model Improvement over Random: {(final_accuracy - 50):.2f}%\")\n",
    "\n",
    "    return final_accuracy\n",
    "\n",
    "# Run the backtest\n",
    "accuracy = directional_backtest(model, dataset, price_scaler, volume_scaler, diff_scaler, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c015b1a-7820-4026-82ca-75de542c229d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
